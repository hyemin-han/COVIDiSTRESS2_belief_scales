setwd("~/Documents/GitHub/COVIDiSTRESS2_belief_scales/R1")
# do some additional analyses for revisions
# factor score correlation
# whole CFA
if (!require("pacman")){
install.packages("pacman")
}
pacman::p_load(tidyverse,
rio,
psych,
car,
lavaan,
sirt,
here,
MASS,
BayesFactor)
# set the current directory
here::i_am('README.md')
here::here()
# load files
load(here('1_conspiracy/1_conspiracy.RData'))
load(here('2_antiexpert/2_antiexpert.Rdata'))
# do whole CFA with to factors
model <- '
CONSP =~ conspirational_think_1 + conspirational_think_2+
conspirational_think_3 + conspirational_think_4
ANTI =~ antiexpert_1 + antiexpert_2+antiexpert_3
CONSP~~ANTI
'
result <- cfa(model,data=data_mi)
result <- cfa(model,data=dat_mi,estimator='DWLS')
result <- cfa(model,data=dat,estimator='DWLS')
result
fitmeasures(result)
summary(result)
summary(result,standardized=T)
table(dat$residing_country)
dat_cor <- dat
for (i in 1:length(langs.include)){
if (i == 1){
# create new matrix
data.aligned <- dat_cor[dat_cor$UserLanguage==langs.include[i],]
# aligned factor score
F <- aligned.factor.scores(mod1$lambda.aligned[i,],
mod1$nu.aligned[i,],
dat_cor[dat_cor$UserLanguage==langs.include[i],variables.consp])
data.aligned$consp <- t(F)
F <- aligned.factor.scores(mod2$lambda.aligned[i,],
mod2$nu.aligned[i,],
dat_cor[dat_cor$UserLanguage==langs.include[i],variables.anti])
data.aligned$anti <- t(F)
}else
{
# bind
current <- dat_cor[dat_cor$UserLanguage==langs.include[i],]
F <- aligned.factor.scores(mod1$lambda.aligned[i,],
mod1$nu.aligned[i,],
current[,variables.consp])
current$consp <- t(F)
F <- aligned.factor.scores(mod2$lambda.aligned[i,],
mod2$nu.aligned[i,],
current[,variables.anti])
current$anti <- t(F)
data.aligned <- rbind(data.aligned,current)
}
}
dat_cor <- dat
for (i in 1:length(langs.include)){
if (i == 1){
# create new matrix
data.aligned <- dat_cor[dat_cor$UserLanguage==langs.include[i],]
}else
{
# bind
current <- dat_cor[dat_cor$UserLanguage==langs.include[i],]
data.aligned <- rbind(data.aligned,current)
}
}
langs.include
picked = sample(seq_len(nrow(dat)),size = floor(.5)*nrow(dat))
picked <- sample(seq_len(nrow(dat)),size = floor(.5)*nrow(dat))
dat.train <- dat[picked,]
dat.val <- dat[-picked,]
# consp
# do configural CFA
model.consp <- 'CONSP =~ conspirational_think_1 + conspirational_think_2+
conspirational_think_3 + conspirational_think_4'
cfa.consp.train <- cfa(model.consp,dat.train,estimator='DWLS',group = 'UserLanguage')
picked <- sample(seq_len(nrow(dat)),size = floor(.5)*nrow(dat))
dat.train <- dat[picked,]
dat.val <- dat[-picked,]
head(picked)
floor(.5)*nrow(dat)
picked <- sample(seq_len(nrow(dat)),size = floor(.5*nrow(dat)))
dat.train <- dat[picked,]
dat.val <- dat[-picked,]
# consp
# do configural CFA
model.consp <- 'CONSP =~ conspirational_think_1 + conspirational_think_2+
conspirational_think_3 + conspirational_think_4'
cfa.consp.train <- cfa(model.consp,dat.train,estimator='DWLS',group = 'UserLanguage')
# randomly pickup 1/2
set.seed(1024)
picked <- sample(seq_len(nrow(dat)),size = floor(.5*nrow(dat)))
dat.train <- dat[picked,]
dat.val <- dat[-picked,]
# consp
# do configural CFA
model.consp <- 'CONSP =~ conspirational_think_1 + conspirational_think_2+
conspirational_think_3 + conspirational_think_4'
cfa.consp.train <- cfa(model.consp,dat.train,estimator='DWLS',group = 'UserLanguage')
# randomly pickup 1/2
set.seed(810305850110)
# randomly pickup 1/2
set.seed(2480746)
picked <- sample(seq_len(nrow(dat)),size = floor(.5*nrow(dat)))
dat.train <- dat[picked,]
dat.val <- dat[-picked,]
# consp
# do configural CFA
model.consp <- 'CONSP =~ conspirational_think_1 + conspirational_think_2+
conspirational_think_3 + conspirational_think_4'
cfa.consp.train <- cfa(model.consp,dat.train,estimator='DWLS',group = 'UserLanguage')
# randomly pickup 1/2
set.seed(2480746)
picked <- sample(seq_len(nrow(dat)),size = floor(.5*nrow(dat)))
dat.train <- dat[picked,]
dat.val <- dat[-picked,]
# consp
# do configural CFA
model.consp <- 'CONSP =~ conspirational_think_1 + conspirational_think_2+
conspirational_think_3 + conspirational_think_4'
cfa.consp.train <- cfa(model.consp,dat.train,estimator='DWLS',group = 'UserLanguage')
# randomly pickup 1/2
set.seed(505)
picked <- sample(seq_len(nrow(dat)),size = floor(.5*nrow(dat)))
dat.train <- dat[picked,]
dat.val <- dat[-picked,]
# consp
# do configural CFA
model.consp <- 'CONSP =~ conspirational_think_1 + conspirational_think_2+
conspirational_think_3 + conspirational_think_4'
cfa.consp.train <- cfa(model.consp,dat.train,estimator='DWLS',group = 'UserLanguage')
# randomly pickup 1/2
set.seed(650)
picked <- sample(seq_len(nrow(dat)),size = floor(.5*nrow(dat)))
dat.train <- dat[picked,]
dat.val <- dat[-picked,]
# consp
# do configural CFA
model.consp <- 'CONSP =~ conspirational_think_1 + conspirational_think_2+
conspirational_think_3 + conspirational_think_4'
cfa.consp.train <- cfa(model.consp,dat.train,estimator='DWLS',group = 'UserLanguage')
table(dat.train$UserLanguage)
table(dat$UserLanguage)
table(langs.include)
# data prep
variables <- c('conspirational_think_1','conspirational_think_2',
'conspirational_think_3','conspirational_think_4',
'antiexpert_1','antiexpert_2','antiexpert_3')
# load files
load(here('1_conspiracy/1_conspiracy.RData'))
load(here('2_antiexpert/2_antiexpert.Rdata'))
# data prep
variables <- c('conspirational_think_1','conspirational_think_2',
'conspirational_think_3','conspirational_think_4',
'antiexpert_1','antiexpert_2','antiexpert_3')
dat<- dat %>% dplyr::select(UserLanguage, #subset df
variables,
-contains("NAppl"))
library(dplyr)
install.packages('dplyr')
install.packages("dplyr")
pacman::p_load(tidyverse,
rio,
psych,
car,
lavaan,
sirt,
here,
MASS,
BayesFactor,
dplyr)
# set the current directory
here::i_am('README.md')
here::here()
# load files
load(here('1_conspiracy/1_conspiracy.RData'))
load(here('2_antiexpert/2_antiexpert.Rdata'))
# data prep
variables <- c('conspirational_think_1','conspirational_think_2',
'conspirational_think_3','conspirational_think_4',
'antiexpert_1','antiexpert_2','antiexpert_3')
dat<- dat %>% dplyr::select(UserLanguage, #subset df
variables,
-contains("NAppl"))
# filter out languages where N < 100
# let's move on to MI test across languages
table(dat$UserLanguage)
# shall be >= 100
# extract  languages where N >= 100
n.langs <- table(dat$UserLanguage)
list.langs <- labels(n.langs)[[1]]
langs.include <- list.langs[n.langs>=100]
n.include <- n.langs[n.langs>=100]
# extract data
for (i in 1:length(langs.include)){
if (i == 1){
dat_mi <- dat[dat$UserLanguage == langs.include[i],]
}else{
current <- dat[dat$UserLanguage == langs.include[i],]
dat_mi <- rbind(dat_mi,current)
}
}
# do whole CFA with to factors
model <- '
CONSP =~ conspirational_think_1 + conspirational_think_2+
conspirational_think_3 + conspirational_think_4
ANTI =~ antiexpert_1 + antiexpert_2+antiexpert_3
CONSP~~ANTI
'
result <- cfa(model,data=dat_mi,estimator='DWLS')
summary(result,standardized=T)
# randomly pickup 1/2
set.seed(650)
picked <- sample(seq_len(nrow(dat_mi)),size = floor(.5*nrow(dat_mi)))
dat.train <- dat_mi[picked,]
dat.val <- dat_mi[-picked,]
# consp
# do configural CFA
model.consp <- 'CONSP =~ conspirational_think_1 + conspirational_think_2+
conspirational_think_3 + conspirational_think_4'
cfa.consp.train <- cfa(model.consp,dat.train,estimator='DWLS',group = 'UserLanguage')
fitMeasures(cfa.consp.train)
# do alignment
var.consp <- c('conspirational_think_1','conspirational_think_2',
'conspirational_think_3','conspirational_think_4')
par <- invariance_alignment_cfa_config(dat = dat.train[,var.consp],
group = dat.train$UserLanguage)
par.consp.train <- invariance_alignment_cfa_config(dat = dat.train[,var.consp],
group = dat.train$UserLanguage)
mod1.consp.train <- invariance.alignment(lambda = par.consp.train$lambda, nu =
par.consp.train$nu, align.scale = c(0.2, 0.4),
align.pow = c(0.25, 0.25))
# test performance
mod1.consp.train$es.invariance['R2',]
# with balidation set
cfa.consp.valid <- cfa(model.consp,dat.valid,estimator='DWLS',group = 'UserLanguage')
# with balidation set
cfa.consp.valid <- cfa(model.consp,dat.val,estimator='DWLS',group = 'UserLanguage')
# do alignment
par.consp.val<- invariance_alignment_cfa_config(dat = dat.val[,var.consp],
group = dat.val$UserLanguage)
mod1.consp.val <- invariance.alignment(lambda = par.consp.val$lambda, nu =
par.consp.val$nu, align.scale = c(0.2, 0.4),
align.pow = c(0.25, 0.25))
# test performance
mod1.consp.val$es.invariance['R2',]
# now anti expert
var.anti <- c('antiexpert_1','antiexpert_2','antiexpert_3')
# train set
cfa.anti.train <- cfa(model.anti,data=dat.train,estimator='DWLS',group = 'UserLanguage')
model.anti <- 'ANTI =~ antiexpert_1 + antiexpert_2+antiexpert_3 '
# train set
cfa.anti.train <- cfa(model.anti,data=dat.train,estimator='DWLS',group = 'UserLanguage')
par.anti.train <- invariance_alignment_cfa_config(dat = dat.train[,var.anti],
group = dat.train$UserLanguage)
mod1.anti.train <- invariance.alignment(lambda = par.anti.train$lambda, nu =
par.anti.train$nu, align.scale = c(0.2, 0.4),
align.pow = c(0.25, 0.25))
# test performance
mod1.anti.train$es.invariance['R2',]
# randomly pickup 1/2
set.seed(248)
picked <- sample(seq_len(nrow(dat_mi)),size = floor(.5*nrow(dat_mi)))
dat.train <- dat_mi[picked,]
dat.val <- dat_mi[-picked,]
# consp
# do configural CFA
model.consp <- 'CONSP =~ conspirational_think_1 + conspirational_think_2+
conspirational_think_3 + conspirational_think_4'
cfa.consp.train <- cfa(model.consp,dat.train,estimator='DWLS',group = 'UserLanguage')
# do alignment
var.consp <- c('conspirational_think_1','conspirational_think_2',
'conspirational_think_3','conspirational_think_4')
par.consp.train <- invariance_alignment_cfa_config(dat = dat.train[,var.consp],
group = dat.train$UserLanguage)
mod1.consp.train <- invariance.alignment(lambda = par.consp.train$lambda, nu =
par.consp.train$nu, align.scale = c(0.2, 0.4),
align.pow = c(0.25, 0.25))
# test performance
mod1.consp.train$es.invariance['R2',]
# do alignment
par.consp.val<- invariance_alignment_cfa_config(dat = dat.val[,var.consp],
group = dat.val$UserLanguage)
mod1.consp.val <- invariance.alignment(lambda = par.consp.val$lambda, nu =
par.consp.val$nu, align.scale = c(0.2, 0.4),
align.pow = c(0.25, 0.25))
# test performance
mod1.consp.val$es.invariance['R2',]
par.anti.train <- invariance_alignment_cfa_config(dat = dat.train[,var.anti],
group = dat.train$UserLanguage)
mod1.anti.train <- invariance.alignment(lambda = par.anti.train$lambda, nu =
par.anti.train$nu, align.scale = c(0.2, 0.4),
align.pow = c(0.25, 0.25))
# test performance
mod1.anti.train$es.invariance['R2',]
table(dat.train$UserLanguage)
table(dat$UserLanguage)
# filter out languages where N < 200 for crossvalidation
# let's move on to MI test across languages
table(dat$UserLanguage)
# shall be >= 200
# extract  languages where N >= 200
n.langs <- table(dat$UserLanguage)
list.langs <- labels(n.langs)[[1]]
langs.include <- list.langs[n.langs>=200]
n.include <- n.langs[n.langs>=200]
# extract data
for (i in 1:length(langs.include)){
if (i == 1){
dat_mi <- dat[dat$UserLanguage == langs.include[i],]
}else{
current <- dat[dat$UserLanguage == langs.include[i],]
dat_mi <- rbind(dat_mi,current)
}
}
# randomly pickup 1/2
set.seed(248)
picked <- sample(seq_len(nrow(dat_mi)),size = floor(.5*nrow(dat_mi)))
dat.train <- dat_mi[picked,]
dat.val <- dat_mi[-picked,]
# consp
# do configural CFA
model.consp <- 'CONSP =~ conspirational_think_1 + conspirational_think_2+
conspirational_think_3 + conspirational_think_4'
cfa.consp.train <- cfa(model.consp,dat.train,estimator='DWLS',group = 'UserLanguage')
# do alignment
var.consp <- c('conspirational_think_1','conspirational_think_2',
'conspirational_think_3','conspirational_think_4')
par.consp.train <- invariance_alignment_cfa_config(dat = dat.train[,var.consp],
group = dat.train$UserLanguage)
mod1.consp.train <- invariance.alignment(lambda = par.consp.train$lambda, nu =
par.consp.train$nu, align.scale = c(0.2, 0.4),
align.pow = c(0.25, 0.25))
# test performance
mod1.consp.train$es.invariance['R2',]
# do alignment
par.consp.val<- invariance_alignment_cfa_config(dat = dat.val[,var.consp],
group = dat.val$UserLanguage)
mod1.consp.val <- invariance.alignment(lambda = par.consp.val$lambda, nu =
par.consp.val$nu, align.scale = c(0.2, 0.4),
align.pow = c(0.25, 0.25))
# test performance
mod1.consp.val$es.invariance['R2',]
par.anti.train <- invariance_alignment_cfa_config(dat = dat.train[,var.anti],
group = dat.train$UserLanguage)
mod1.anti.train <- invariance.alignment(lambda = par.anti.train$lambda, nu =
par.anti.train$nu, align.scale = c(0.2, 0.4),
align.pow = c(0.25, 0.25))
# test performance
mod1.anti.train$es.invariance['R2',]
# do alignment
par.anti.val<- invariance_alignment_cfa_config(dat = dat.val[,var.anti],
group = dat.val$UserLanguage)
mod1.anti.val <- invariance.alignment(lambda = par.anti.val$lambda, nu =
par.anti.val$nu, align.scale = c(0.2, 0.4),
align.pow = c(0.25, 0.25))
# test performance
mod1.anti.val$es.invariance['R2',]
#  loadings intercepts
#0.9802152  0.9898060
# randomly pickup 1/2
set.seed(81234)
picked <- sample(seq_len(nrow(dat_mi)),size = floor(.5*nrow(dat_mi)))
dat.train <- dat_mi[picked,]
dat.val <- dat_mi[-picked,]
# do alignment
par.anti.val<- invariance_alignment_cfa_config(dat = dat.val[,var.anti],
group = dat.val$UserLanguage)
# randomly pickup 1/2
set.seed(12345)
picked <- sample(seq_len(nrow(dat_mi)),size = floor(.5*nrow(dat_mi)))
dat.train <- dat_mi[picked,]
dat.val <- dat_mi[-picked,]
# with balidation set
cfa.anti.valid <- cfa(model.anti,dat.val,estimator='DWLS',group = 'UserLanguage')
# do alignment
par.anti.val<- invariance_alignment_cfa_config(dat = dat.val[,var.anti],
group = dat.val$UserLanguage)
# filter out languages where N < 300 for crossvalidation
# let's move on to MI test across languages
table(dat$UserLanguage)
# shall be >= 300
# extract  languages where N >= 300
n.langs <- table(dat$UserLanguage)
list.langs <- labels(n.langs)[[1]]
langs.include <- list.langs[n.langs>=300]
n.include <- n.langs[n.langs>=300]
# extract data
for (i in 1:length(langs.include)){
if (i == 1){
dat_mi <- dat[dat$UserLanguage == langs.include[i],]
}else{
current <- dat[dat$UserLanguage == langs.include[i],]
dat_mi <- rbind(dat_mi,current)
}
}
# randomly pickup 1/2
set.seed(12345)
picked <- sample(seq_len(nrow(dat_mi)),size = floor(.5*nrow(dat_mi)))
dat.train <- dat_mi[picked,]
dat.val <- dat_mi[-picked,]
# do alignment
par.anti.val<- invariance_alignment_cfa_config(dat = dat.val[,var.anti],
group = dat.val$UserLanguage)
mod1.anti.val <- invariance.alignment(lambda = par.anti.val$lambda, nu =
par.anti.val$nu, align.scale = c(0.2, 0.4),
align.pow = c(0.25, 0.25))
# test performance
mod1.anti.val$es.invariance['R2',]
par.anti.train <- invariance_alignment_cfa_config(dat = dat.train[,var.anti],
group = dat.train$UserLanguage)
mod1.anti.train <- invariance.alignment(lambda = par.anti.train$lambda, nu =
par.anti.train$nu, align.scale = c(0.2, 0.4),
align.pow = c(0.25, 0.25))
# test performance
mod1.anti.train$es.invariance['R2',]
par.consp.train <- invariance_alignment_cfa_config(dat = dat.train[,var.consp],
group = dat.train$UserLanguage)
mod1.consp.train <- invariance.alignment(lambda = par.consp.train$lambda, nu =
par.consp.train$nu, align.scale = c(0.2, 0.4),
align.pow = c(0.25, 0.25))
# test performance
mod1.consp.train$es.invariance['R2',]
par.consp.val<- invariance_alignment_cfa_config(dat = dat.val[,var.consp],
group = dat.val$UserLanguage)
mod1.consp.val <- invariance.alignment(lambda = par.consp.val$lambda, nu =
par.consp.val$nu, align.scale = c(0.2, 0.4),
align.pow = c(0.25, 0.25))
# test performance
mod1.consp.val$es.invariance['R2',]
lavInspect(fit.configural)
inspect(fit.configural,what="std")$lambda
inspect(fit.configural,what="std")
test<-inspect(fit.configural,what="std")
# print out factor loadings
# consp
load(here('1_conspiracy/1_conspiracy.RData'))
inspect(fit.configural,what="std")
mod1$lambda.aligned
inspect(fit.configural)
test$`ZH-T`
mod1$lambda.aligned
# print out factor loadings
# consp
load(here('1_conspiracy/1_conspiracy.RData'))
inspect(fit.configural,what="std")$EN
mod1$lambda.aligned
inspect(fit.configural)$EN
summary(result,standardized=T)
# print out factor loadings
# consp
load(here('1_conspiracy/1_conspiracy.RData'))
par
par$lambda
test<-summary(fit.configural)
test
test$PE
summary(fit.configural)
par$lambda
summary(fit.configural,standardized=T)
par$lambda
1.4184283/0.6449334
1.3579399/1.6185366
View(par$lambda)
View(par$nu)
View(mod1$lambda.aligned)
View(mod1$nu.aligned)
# anti
load(here('2_antiexpert/2_antiexpert.Rdata'))
View(par$lambda)
View(par$nu)
View(mod2$lambda.aligned)
View(mod2$nu.aligned)
View(mod2$nu.aligned)
